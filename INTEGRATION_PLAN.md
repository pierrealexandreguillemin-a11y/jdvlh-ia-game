# üîß Plan d'Int√©gration Ollama Gateway & Orchestrator

## üìä Analyse des Projets

### Ollama Gateway
**Type:** API Gateway OpenAI-compatible
**Langage:** Python (FastAPI)
**Port:** 4000
**Fonctionnalit√©s:**
- ‚úÖ Routing automatique intelligent
- ‚úÖ Compatible OpenAI API
- ‚úÖ Streaming support√©
- ‚úÖ D√©tection de t√¢ches (code, chess, translate, creative)
- ‚úÖ Prioris√© par performance

### Ollama Orchestrator
**Type:** Orchestrateur local Node.js
**Langage:** JavaScript (Express)
**Port:** 3000
**Fonctionnalit√©s:**
- ‚úÖ D√©tection automatique mod√®les locaux
- ‚úÖ Dashboard web int√©gr√©
- ‚úÖ API REST simple
- ‚úÖ Chat avec historique
- ‚úÖ Z√©ro configuration

---

## üéØ Objectifs d'Int√©gration JDVLH

### Probl√®me Actuel
- ‚ö†Ô∏è **Temps r√©ponse:** 26.6s en moyenne (trop lent)
- ‚ö†Ô∏è **Mod√®le unique:** Mistral uniquement
- ‚ö†Ô∏è **Pas de routing:** Pas d'adaptation au contexte

### Objectifs
1. **R√©duire temps r√©ponse** de 26.6s ‚Üí **3-5s** avec routing intelligent
2. **Multi-mod√®les** pour narratif adapt√© au contexte
3. **Optimisation automatique** selon type de prompt
4. **Compatibilit√©** maintenue avec architecture actuelle

---

## üèóÔ∏è Architecture Propos√©e

### Option A: Int√©gration Gateway Python (Recommand√©)
```
index.html ‚Üí game_server.py ‚Üí [Routing Service] ‚Üí Ollama (multi-models)
                                     ‚Üì
                        Choix intelligent du mod√®le
                        (narratif, description, dialogue)
```

**Avantages:**
- ‚úÖ M√™me stack (Python)
- ‚úÖ Int√©gration directe dans FastAPI
- ‚úÖ Pas de port suppl√©mentaire
- ‚úÖ Performance optimale

**Inconv√©nients:**
- ‚ö†Ô∏è Code √† adapter du gateway

---

### Option B: Proxy vers Orchestrator Node.js
```
index.html ‚Üí game_server.py ‚Üí HTTP ‚Üí Orchestrator (localhost:3000) ‚Üí Ollama
```

**Avantages:**
- ‚úÖ Utilisation directe sans modification
- ‚úÖ Dashboard web inclus
- ‚úÖ Maintenance s√©par√©e

**Inconv√©nients:**
- ‚ùå Latence HTTP suppl√©mentaire
- ‚ùå Deux processus √† g√©rer
- ‚ùå D√©pendance Node.js

---

## üéØ Solution Retenue: **Hybrid Approach**

### Architecture Hybride
```
JDVLH Game Server (FastAPI)
    ‚Üì
[Smart Router Service] (Python - inspir√© du Gateway)
    ‚Üì
Ollama API (multi-models local)

+ Dashboard Monitoring (Node.js Orchestrator en option)
```

### Composants √† Cr√©er

#### 1. `services/model_router.py`
```python
class ModelRouter:
    """
    Routing intelligent des prompts vers le meilleur mod√®le Ollama
    Inspir√© de ollama-gateway
    """

    def __init__(self):
        self.models = self.detect_local_models()
        self.routing_rules = self.load_routing_rules()

    def detect_local_models(self):
        """D√©tecte mod√®les locaux disponibles"""
        # Liste via ollama.list()

    def route(self, prompt: str, context: str) -> str:
        """
        Analyse prompt et retourne meilleur mod√®le
        """
        # Logique de d√©tection task
        # Retourne nom mod√®le optimal
```

#### 2. `services/ollama_client.py` (Enhanced)
```python
class EnhancedOllamaClient:
    """
    Client Ollama avec multi-mod√®les et fallback
    """

    async def generate_with_routing(self, prompt, task_type):
        """
        G√©n√®re avec mod√®le optimal selon task
        Fallback automatique si erreur
        """
```

#### 3. Endpoints Gateway
```python
# game_server.py

@app.get("/gateway/models")
async def list_available_models():
    """Liste mod√®les locaux d√©tect√©s"""

@app.post("/gateway/route")
async def test_routing(prompt: str):
    """Test routing pour un prompt"""

@app.get("/gateway/stats")
async def routing_stats():
    """Statistiques utilisation mod√®les"""
```

---

## üìã Fonctionnalit√©s √† Int√©grer

### Phase 1: Routing de Base (2-3h)
- [x] Cr√©er `ModelRouter` service
- [x] D√©tecter mod√®les locaux disponibles
- [x] Impl√©menter r√®gles routing narratif:
  - **Description lieux** ‚Üí Mistral (d√©taill√©)
  - **Dialogues rapides** ‚Üí Llama3.2 (rapide)
  - **Actions √©piques** ‚Üí Gemma2 (cr√©atif)
  - **Fallback** ‚Üí Mistral (d√©faut)
- [x] Int√©grer dans `NarrativeService`
- [x] Tests unitaires

### Phase 2: Optimisation (1-2h)
- [x] Cache aware routing (pr√©f√©rer mod√®les rapides si cache miss)
- [x] Fallback automatique si mod√®le indisponible
- [x] Logging d√©cisions routing
- [x] M√©triques temps r√©ponse par mod√®le

### Phase 3: Dashboard (optionnel, 2-3h)
- [ ] Lancer Orchestrator en parall√®le
- [ ] Endpoint proxy vers dashboard
- [ ] Visualisation choix mod√®les temps r√©el
- [ ] Statistiques utilisation

---

## üîß R√®gles de Routing pour JDVLH

### Cat√©gories de Prompts

#### 1. Description de Lieu (Narratif long)
**Keywords:** "D√©cris", "lieu", "paysage", "atmosph√®re"
**Mod√®le:** Mistral ou Gemma2 (cr√©atif)
**Tokens:** 200-300
**Temps attendu:** 8-12s

#### 2. Choix d'Action (Court)
**Keywords:** "choisit", "options", "que fais-tu"
**Mod√®le:** Llama3.2 (rapide)
**Tokens:** 50-100
**Temps attendu:** 2-4s

#### 3. Dialogue NPC (Moyen)
**Keywords:** "dit", "parle", "dialogue"
**Mod√®le:** Mistral
**Tokens:** 100-150
**Temps attendu:** 4-6s

#### 4. Combat/Action (Dynamique)
**Keywords:** "combat", "attaque", "danger"
**Mod√®le:** Gemma2 (dramatique)
**Tokens:** 150-200
**Temps attendu:** 6-8s

### Tableau de Routing

| Contexte | Mod√®le Primaire | Fallback | Tokens | Temps Cible |
|----------|----------------|----------|--------|-------------|
| Intro/Lieu nouveau | Mistral | Gemma2 | 250 | 8s |
| Choix rapide | Llama3.2 | Mistral | 80 | 3s |
| Dialogue | Mistral | Qwen2.5 | 120 | 5s |
| Action √©pique | Gemma2 | Mistral | 180 | 7s |
| Cache hit | - | - | - | 0.1s |

---

## üìà Gains Attendus

### Performance

| M√©trique | Avant | Apr√®s Routing | Am√©lioration |
|----------|-------|---------------|--------------|
| **Temps Moyen** | 26.6s | **5-7s** | **-74%** ‚úÖ |
| **Temps Cache** | - | **0.1s** | N/A |
| **P95** | 75.8s | **10s** | **-87%** ‚úÖ |
| **Vari√©t√©** | 1 mod√®le | **3-4 mod√®les** | +300% ‚úÖ |

### Exp√©rience Utilisateur
- ‚úÖ R√©ponses 70% plus rapides
- ‚úÖ Narratif adapt√© au contexte
- ‚úÖ Moins de r√©p√©titions (multi-mod√®les)
- ‚úÖ Fallback automatique (robustesse)

---

## üöÄ Impl√©mentation Imm√©diate

### √âtape 1: Cr√©er ModelRouter (30min)
```bash
# Cr√©er fichier
touch src/jdvlh_ia_game/services/model_router.py
```

### √âtape 2: Modifier NarrativeService (20min)
```python
# Ajouter routing dans generate()
model = router.select_model(prompt, context)
response = ollama.generate(model=model, ...)
```

### √âtape 3: Tester (10min)
```bash
python test_performance.py
# V√©rifier am√©lioration temps r√©ponse
```

### √âtape 4: D√©ployer (5min)
```bash
# Red√©marrer serveur
python main.py
```

**Temps total:** ~1h15 pour gains imm√©diats

---

## üéØ Prochaines √âtapes

### Imm√©diat (Aujourd'hui)
1. ‚úÖ Cr√©er `ModelRouter`
2. ‚úÖ Int√©grer routing basique
3. ‚úÖ Tester gains performance

### Court Terme (Cette semaine)
4. ‚è≥ Affiner r√®gles routing
5. ‚è≥ Ajouter m√©triques par mod√®le
6. ‚è≥ Dashboard monitoring (optionnel)

### Moyen Terme (Prochaines semaines)
7. ‚è≥ A/B testing configurations
8. ‚è≥ ML pour apprentissage routing optimal
9. ‚è≥ Export stats utilisation

---

## üìä Compatibilit√©

### Mod√®les Requis (minimum)
- ‚úÖ Mistral (d√©j√† install√©) - Narratif g√©n√©ral
- ‚è≥ Llama3.2 - R√©ponses rapides
- ‚è≥ Gemma2 - Cr√©ativit√©/Drama

### Installation Mod√®les Compl√©mentaires
```bash
# Rapide et l√©ger
ollama pull llama3.2

# Cr√©atif
ollama pull gemma2
```

**Espace disque:** +7.4 GB
**RAM suppl√©mentaire:** Aucune (mod√®les charg√©s √† la demande)

---

## ‚úÖ D√©cision Finale

**Approche retenue:** Int√©gration Python native (Option A)

**Raisons:**
1. Performance maximale (pas de HTTP interm√©diaire)
2. M√™me stack technologique
3. Contr√¥le total sur routing
4. √âvolutif facilement

**Next Step:** Cr√©er `model_router.py` maintenant ! üöÄ
