# ‚ö° GUIDE D'ACTION RAPIDE - JDR IA Game

**Date**: 22 Novembre 2025  
**Objectif**: Optimiser et d√©marrer l'impl√©mentation en 2 heures

---

## üéØ VERDICT FINAL

‚úÖ **VOTRE PROJET EST D√âJ√Ä MEILLEUR QUE LES SOLUTIONS GITHUB**

**Ce que vous avez d√©j√†** :

- ‚úÖ Backend FastAPI production-ready
- ‚úÖ ModelRouter intelligent (routing multi-mod√®les)
- ‚úÖ NarrativeMemory avanc√©e (coh√©rence narrative)
- ‚úÖ S√©curit√© enfants (filtres, rate-limiting)
- ‚úÖ Persistance SQLite + cache

**Ce qui manque** :

- ‚è≥ Optimisations performance (26.6s ‚Üí 2.5s)
- ‚è≥ Client Godot 3D
- ‚è≥ Features JDR avanc√©es (combat, inventaire, qu√™tes)

---

## üìä COMPARAISON AVEC GITHUB

| Solution           | Stack        | IA Locale | Qualit√© | Votre Projet   |
| ------------------ | ------------ | --------- | ------- | -------------- |
| td-llm-dnd         | Streamlit    | ‚úÖ        | 6/10    | **MEILLEUR**   |
| Dungeo_ai          | Python       | ‚úÖ        | 7/10    | **MEILLEUR**   |
| ai-dungeon-master  | Node/Discord | ‚úÖ        | 8/10    | **√âQUIVALENT** |
| GodotDynamicDialog | Godot        | ‚ùå API    | 9/10    | **√Ä INT√âGRER** |

**Conclusion** : Vous √™tes sur la bonne voie, continuez !

---

## üöÄ ACTIONS IMM√âDIATES (2 HEURES)

### √âTAPE 1 : Optimisations Critiques (30min)

#### 1.1 Modifier config.yaml

```bash
cd C:\Dev\jdvlh-ia-game
code config.yaml
```

**Changements √† faire** :

```yaml
ollama:
  model: mistral
  max_retries: 3
  temperature: 0.75 # Au lieu de 0.8
  max_tokens: 150 # AU LIEU DE 400 ‚ö° CRITIQUE

cache:
  dir: cache
  ttl: 7200 # D√©j√† bon
  pregenerate: true # ‚ö° AJOUTER CETTE LIGNE

prompts:
  system: "Tu es un ma√Ætre du jeu D&D/Tolkien pour enfants francophones de 10-14 ans. Raconte TOUJOURS en FRAN√áAIS une histoire √©pique et immersive. 8-12 phrases maximum, descriptions riches mais concises. IMPORTANT: JAMAIS d'anglais, TOUJOURS du fran√ßais."
```

**Gain attendu** : **-50% temps de r√©ponse**

#### 1.2 Installer mod√®les suppl√©mentaires

```bash
# Mod√®le rapide (pour choix courts)
ollama pull llama3.2

# Mod√®le cr√©atif (pour descriptions √©piques)
ollama pull gemma2
```

**Temps** : 5-10 minutes (t√©l√©chargement)  
**Gain attendu** : **-40% temps moyen**

#### 1.3 Int√©grer ModelRouter

```bash
code src/jdvlh_ia_game/services/narrative.py
```

**Ajouter au d√©but du fichier** :

```python
from .model_router import get_router, TaskType
```

**Modifier la classe NarrativeService** :

```python
class NarrativeService:
    def __init__(self):
        self.cache = CacheService()
        self.memory = NarrativeMemory()  # ‚ö° D√©j√† pr√©sent
        self.router = get_router()       # ‚ö° AJOUTER CETTE LIGNE

    async def generate_narrative(self, prompt: str, context: str = ""):
        # ‚ö° AJOUTER CES 2 LIGNES
        model, options = self.router.select_model(prompt, context)

        # Modifier l'appel Ollama pour utiliser le mod√®le s√©lectionn√©
        response = ollama.generate(
            model=model,  # ‚ö° Au lieu de "mistral"
            prompt=prompt,
            **options  # ‚ö° Au lieu de hardcoded options
        )

        return response
```

**Gain attendu** : **+100% qualit√©, -40% temps**

#### 1.4 Tester les optimisations

```bash
# Lancer le serveur
python main.py

# Dans un autre terminal, tester
python test_performance.py
```

**Objectif** : Temps moyen < 3 secondes ‚úÖ

---

### √âTAPE 2 : D√©cision Orchestration (15min)

#### Quelle solution utiliser ?

| Outil                    | Avantages                                            | Inconv√©nients                          | Recommandation          |
| ------------------------ | ---------------------------------------------------- | -------------------------------------- | ----------------------- |
| **ModelRouter int√©gr√©**  | ‚úÖ D√©j√† dans code<br>‚úÖ Python natif<br>‚úÖ 0 latence | ‚ùå Aucun                               | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê **UTILISER** |
| Ollama Gateway           | ‚úÖ Compatible OpenAI<br>‚úÖ Pour outils externes      | ‚ùå Serveur s√©par√©<br>‚ùå Latence r√©seau | ‚ö†Ô∏è Phase 2 seulement    |
| Ollama Orchestrator Node | ‚úÖ Dashboard joli                                    | ‚ùå Node.js<br>‚ùå Bridge requis         | üîß Tests uniquement     |
| Scripts Bash             | ‚úÖ Ultra-simple                                      | ‚ùå Pas d'API                           | üîß Debug uniquement     |

**D√âCISION** : ‚úÖ **Utiliser ModelRouter int√©gr√©** (d√©j√† fait dans code ci-dessus)

**Utilisation des autres outils** :

```bash
# Ollama Orchestrator - Pour tests manuels mod√®les
cd C:\Dev\ollama-orchestrator
npm start
# Ouvrir http://localhost:3000

# Ollama Gateway - Si vous utilisez Claude-Code/Continue
cd C:\Dev\ollama-gateway
python main.py
# Configure VSCode: apiBase = http://localhost:4000/v1

# Scripts Bash Claude - Tests rapides terminal
./ask.sh coder "Write a function"
./ask.sh chess "Best move?"
```

---

### √âTAPE 3 : Comparer avec GitHub (30min)

#### Projets √† analyser en d√©tail

**1. GodotDynamicDialog** (PRIORIT√â HAUTE)

```bash
# Cloner pour r√©f√©rence
cd C:\Dev
git clone https://github.com/Godot-Dynamic-Dialog/GodotDynamicDialog.git
```

**√Ä √©tudier** :

- Structure projet Godot
- Int√©gration WebSocket
- UI dialogue
- Gestion contexte

**√Ä r√©utiliser** :

- ‚úÖ Structure sc√®nes Godot
- ‚úÖ Syst√®me dialogue UI
- ‚ö†Ô∏è Adapter pour Ollama local (au lieu d'OpenAI API)

**2. ai-dungeon-master** (INSPIRATION)

```bash
cd C:\Dev
git clone https://github.com/davidpm1021/ai-dungeon-master.git
```

**√Ä √©tudier** :

- Dual-model pattern (critique + draft)
- M√©moire vectorielle (ChromaDB)
- Service orchestration

**√Ä r√©utiliser** :

- ‚úÖ Pattern dual-model (pour validation narration)
- ‚ö†Ô∏è M√©moire vectorielle (Phase 2 si n√©cessaire)

**3. fastapi_websocket_pubsub** (FUTUR)

```bash
cd C:\Dev
git clone https://github.com/permitio/fastapi_websocket_pubsub.git
```

**√Ä √©tudier** :

- PubSub multi-serveurs
- Scalabilit√©

**Quand utiliser** :

- ‚è≥ Phase 2+ (quand multi-joueurs avanc√©)

---

### √âTAPE 4 : Setup Godot (45min)

#### 4.1 Installer Godot 4.3

```bash
# T√©l√©charger Godot 4.3
# https://godotengine.org/download

# Installer dans C:\Dev\Godot\
```

#### 4.2 Cr√©er projet Godot

```bash
# Ouvrir Godot
# New Project
# Nom: jdvlh-godot-client
# Location: C:\Dev\jdvlh-godot-client
# Renderer: Forward+ (pour 3D)
```

#### 4.3 Structure initiale

```
jdvlh-godot-client/
‚îú‚îÄ‚îÄ project.godot
‚îú‚îÄ‚îÄ scenes/
‚îÇ   ‚îú‚îÄ‚îÄ main_menu.tscn
‚îÇ   ‚îú‚îÄ‚îÄ game_world.tscn
‚îÇ   ‚îî‚îÄ‚îÄ ui/
‚îÇ       ‚îú‚îÄ‚îÄ hud.tscn
‚îÇ       ‚îî‚îÄ‚îÄ dialogue.tscn
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ network_manager.gd
‚îÇ   ‚îî‚îÄ‚îÄ game_state.gd
‚îî‚îÄ‚îÄ assets/
    ‚îî‚îÄ‚îÄ placeholder/
```

#### 4.4 Cr√©er NetworkManager

**Fichier** : `scripts/network_manager.gd`

```gdscript
extends Node

var socket := WebSocketPeer.new()
var url := "ws://localhost:8000/ws/"

signal narrative_received(text: String)

func _ready():
    var player_id = str(randi())
    socket.connect_to_url(url + player_id)

func _process(_delta):
    socket.poll()
    if socket.get_ready_state() == WebSocketPeer.STATE_OPEN:
        while socket.get_available_packet_count():
            var packet = socket.get_packet()
            var data = JSON.parse_string(packet.get_string_from_utf8())
            _handle_message(data)

func _handle_message(data: Dictionary):
    if data.get("type") == "narrative_update":
        narrative_received.emit(data.text)

func send_choice(choice_text: String):
    var message = {
        "type": "player_choice",
        "choice": choice_text
    }
    socket.send_text(JSON.stringify(message))
```

#### 4.5 Test connexion

```bash
# Terminal 1: Lancer backend
cd C:\Dev\jdvlh-ia-game
python main.py

# Terminal 2: Godot
# Ouvrir projet
# Run (F5)
# V√©rifier console : "Connected to server"
```

---

## üìã CHECKLIST COMPL√àTE

### Phase 0: Optimisations (2h) üî¥ AUJOURD'HUI

- [ ] Modifier `config.yaml` (max_tokens: 150)
- [ ] Installer llama3.2 et gemma2
- [ ] Int√©grer ModelRouter dans NarrativeService
- [ ] Tester performance (< 3s)
- [ ] Cloner GodotDynamicDialog pour r√©f√©rence
- [ ] Setup projet Godot basique
- [ ] Test connexion WebSocket

**R√©sultat attendu** :

- ‚úÖ Temps r√©ponse < 3s
- ‚úÖ Multi-mod√®les fonctionnel
- ‚úÖ Godot connect√© au backend

### Phase 1: Features JDR (1 semaine) üü° SEMAINE PROCHAINE

- [ ] Cr√©er models/game_entities.py (Player, Item, Spell, etc.)
- [ ] Impl√©menter services/combat_engine.py
- [ ] Impl√©menter services/inventory_manager.py
- [ ] Impl√©menter services/quest_manager.py
- [ ] Impl√©menter services/character_progression.py
- [ ] Tests unitaires (pytest)

### Phase 2: Client Godot (1 semaine) üü¢ DANS 2 SEMAINES

- [ ] Player controller 3D
- [ ] UI syst√®me (HUD, inventaire, dialogue)
- [ ] Animations de base
- [ ] Int√©gration backend compl√®te

### Phase 3: Visuels (2 semaines) ‚ö™ DANS 1 MOIS

- [ ] Mod√®les 3D low-poly
- [ ] Animations avanc√©es
- [ ] Effets visuels
- [ ] Audio (musique + SFX)

---

## üéØ PROCHAINES 2 HEURES - PLAN D√âTAILL√â

### 08:00 - 08:30 : Optimisations Config

```bash
# 1. Modifier config.yaml
code C:\Dev\jdvlh-ia-game\config.yaml
# Changer max_tokens: 150
# Ajouter pregenerate: true

# 2. Installer mod√®les
ollama pull llama3.2
ollama pull gemma2
```

### 08:30 - 09:00 : Int√©gration ModelRouter

```bash
# 1. Modifier narrative.py
code C:\Dev\jdvlh-ia-game\src\jdvlh_ia_game\services\narrative.py

# 2. Ajouter:
# from .model_router import get_router
# self.router = get_router()
# model, options = self.router.select_model(...)
```

### 09:00 - 09:15 : Tests Performance

```bash
# Lancer serveur
python main.py

# Nouveau terminal
python test_performance.py

# V√©rifier: temps < 3s ‚úÖ
```

### 09:15 - 09:30 : Cloner R√©f√©rences GitHub

```bash
cd C:\Dev
git clone https://github.com/Godot-Dynamic-Dialog/GodotDynamicDialog.git
git clone https://github.com/davidpm1021/ai-dungeon-master.git
```

### 09:30 - 10:00 : Setup Godot

```bash
# 1. T√©l√©charger + installer Godot 4.3
# 2. Cr√©er projet: jdvlh-godot-client
# 3. Cr√©er NetworkManager.gd (code ci-dessus)
# 4. Test connexion WebSocket
```

---

## üí° COMMANDES DE R√âF√âRENCE

### Backend

```bash
# D√©marrer serveur
cd C:\Dev\jdvlh-ia-game
python main.py

# Tests performance
python test_performance.py

# Tests unitaires
pytest tests/

# Voir logs
tail -f logs/game.log
```

### Ollama

```bash
# Lister mod√®les
ollama list

# Installer mod√®le
ollama pull llama3.2

# Tester mod√®le
ollama run llama3.2 "Bonjour"

# Stats utilisation
ollama ps
```

### Godot

```bash
# Lancer projet
godot --path C:\Dev\jdvlh-godot-client

# Run scene (depuis Godot)
F5

# Export Windows
godot --export "Windows Desktop" game.exe
```

### Git

```bash
# Commit optimisations
cd C:\Dev\jdvlh-ia-game
git add .
git commit -m "perf: optimize ollama config and integrate model router"
git push
```

---

## üìä METRICS DE SUCC√àS

### Avant Optimisations

```
Temps moyen: 26.6s
Mod√®les utilis√©s: 1 (Mistral)
Coh√©rence: 7/10
```

### Apr√®s Optimisations (Objectif)

```
Temps moyen: < 3s  ‚úÖ
Mod√®les utilis√©s: 3+ (Mistral, Llama3.2, Gemma2)
Coh√©rence: 9/10 ‚úÖ
```

### MVP Godot (Semaine 4)

```
Backend: ‚úÖ Complet
Godot Client: ‚úÖ Fonctionnel
Features JDR: ‚úÖ Combat, inventaire, qu√™tes
Visuels: ‚è≥ Placeholders low-poly
```

### Version Finale (Mois 2)

```
Tout ci-dessus +
Visuels 3D: ‚úÖ Low-poly complets
Animations: ‚úÖ Toutes actions
Audio: ‚úÖ Musique + SFX
Features avanc√©es: ‚úÖ Crafting, √©conomie
```

---

## üéâ CONCLUSION

**Vous avez TOUT ce qu'il faut pour r√©ussir** :

‚úÖ Backend solide et bien architectur√©  
‚úÖ Syst√®me IA avanc√© (m√©moire + routing)  
‚úÖ Outils d'orchestration disponibles  
‚úÖ R√©f√©rences GitHub pour inspiration  
‚úÖ Roadmap claire et r√©aliste

**Action NOW** :

1. ‚ö° Appliquer optimisations (30min)
2. üß™ Tester performance (15min)
3. üéÆ Setup Godot (45min)
4. üöÄ D√©marrer Phase 1 (semaine prochaine)

**Bon courage ! üî•**

---

**Document g√©n√©r√© le 22 Novembre 2025**  
**Version**: 1.0 - Guide Action Rapide
